{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Runme_blinkdetection.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"WVL8w9Y_Ls_-","colab_type":"code","colab":{}},"source":["#Reference:https://www.pyimagesearch.com/\n","#This file  detects blinks, their parameters and analyzes them[the final main code]\n","# import the necessary packages\n","from __future__ import print_function\n","\n","from scipy.spatial import distance as dist\n","import scipy.ndimage.filters as signal\n","\n","from imutils import face_utils\n","\n","import datetime\n","import imutils\n","import dlib\n","\n","import matplotlib.pyplot as plt\n","import tkinter as tk\n","from tkinter import*\n","from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n","from scipy.ndimage.interpolation import shift\n","import pickle\n","from queue import Queue\n","\n","# import the necessary packages\n","\n","import numpy as np\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyQsslTXLtAI","colab_type":"code","colab":{}},"source":["# this \"adjust_gamma\" function directly taken from : https://www.pyimagesearch.com/2015/10/05/opencv-gamma-correction/\n","def adjust_gamma(image, gamma=1.0):\n","    # build a lookup table mapping the pixel values [0, 255] to\n","    # their adjusted gamma values\n","    invGamma = 1.0 / gamma\n","    table = np.array([((i / 255.0) ** invGamma) * 255\n","                      for i in np.arange(0, 256)]).astype(\"uint8\")\n","\n","    # apply gamma correction using the lookup table\n","    return cv2.LUT(image, table)\n","\n","#\n","\n","\n","#\n","\n","def blink_detector(output_textfile,input_video):\n","\n","\n","\n","    Q = Queue(maxsize=7)\n","\n","    FRAME_MARGIN_BTW_2BLINKS=3\n","    MIN_AMPLITUDE=0.04\n","    MOUTH_AR_THRESH=0.35\n","    MOUTH_AR_THRESH_ALERT=0.30\n","    MOUTH_AR_CONSEC_FRAMES=20\n","\n","    EPSILON=0.01  # for discrete derivative (avoiding zero derivative)\n","    class Blink():\n","        def __init__(self):\n","\n","            self.start=0 #frame\n","            self.startEAR=1\n","            self.peak=0  #frame\n","            self.peakEAR = 1\n","            self.end=0   #frame\n","            self.endEAR=0\n","            self.amplitude=(self.startEAR+self.endEAR-2*self.peakEAR)/2\n","            self.duration = self.end-self.start+1\n","            self.EAR_of_FOI=0 #FrameOfInterest\n","            self.values=[]\n","            self.velocity=0  #Eye-closing velocity\n","\n","\n","\n","    def eye_aspect_ratio(eye):\n","        # compute the euclidean distances between the two sets of\n","        # vertical eye landmarks (x, y)-coordinates\n","        A = dist.euclidean(eye[1], eye[5])\n","        B = dist.euclidean(eye[2], eye[4])\n","\n","        # compute the euclidean distance between the horizontal\n","        # eye landmark (x, y)-coordinates\n","        C = dist.euclidean(eye[0], eye[3])\n","\n","        if C<0.1:           #practical finetuning due to possible numerical issue as a result of optical flow\n","            ear=0.3\n","        else:\n","            # compute the eye aspect ratio\n","            ear = (A + B) / (2.0 * C)\n","        if ear>0.45:        #practical finetuning due to possible numerical issue as a result of optical flow\n","            ear=0.45\n","        # return the eye aspect ratio\n","        return ear\n","\n","    def mouth_aspect_ratio(mouth):\n","\n","        A = dist.euclidean(mouth[14], mouth[18])\n","\n","        C = dist.euclidean(mouth[12], mouth[16])\n","\n","        if C<0.1:           #practical finetuning\n","            mar=0.2\n","        else:\n","            # compute the mouth aspect ratio\n","            mar = (A ) / (C)\n","\n","        # return the mouth aspect ratio\n","        return mar\n","\n","\n","    def EMERGENCY(ear, COUNTER):\n","        if ear < 0.21:\n","            COUNTER += 1\n","\n","            if COUNTER >= 50:\n","                print('EMERGENCY SITUATION (EYES TOO LONG CLOSED)')\n","                print(COUNTER)\n","                COUNTER = 0\n","        else:\n","            COUNTER=0\n","        return COUNTER\n","\n","    def Linear_Interpolate(start,end,N):\n","        m=(end-start)/(N+1)\n","        x=np.linspace(1,N,N)\n","        y=m*(x-0)+start\n","        return list(y)\n","\n","    def Ultimate_Blink_Check():\n","        #Given the input \"values\", retrieve blinks and their quantities\n","        retrieved_blinks=[]\n","        MISSED_BLINKS=False\n","        values=np.asarray(Last_Blink.values)\n","        THRESHOLD=0.4*np.min(values)+0.6*np.max(values)   # this is to split extrema in highs and lows\n","        N=len(values)\n","        Derivative=values[1:N]-values[0:N-1]    #[-1 1] is used for derivative\n","        i=np.where(Derivative==0)\n","        if len(i[0])!=0:\n","            for k in i[0]:\n","                if k==0:\n","                    Derivative[0]=-EPSILON\n","                else:\n","                    Derivative[k]=EPSILON*Derivative[k-1]\n","        M=N-1    #len(Derivative)\n","        ZeroCrossing=Derivative[1:M]*Derivative[0:M-1]\n","        x = np.where(ZeroCrossing < 0)\n","        xtrema_index=x[0]+1\n","        XtremaEAR=values[xtrema_index]\n","        Updown=np.ones(len(xtrema_index))        # 1 means high, -1 means low for each extremum\n","        Updown[XtremaEAR<THRESHOLD]=-1           #this says if the extremum occurs in the upper/lower half of signal\n","        #concatenate the beginning and end of the signal as positive high extrema\n","        Updown=np.concatenate(([1],Updown,[1]))\n","        XtremaEAR=np.concatenate(([values[0]],XtremaEAR,[values[N-1]]))\n","        xtrema_index = np.concatenate(([0], xtrema_index,[N - 1]))\n","        ##################################################################\n","\n","        Updown_XeroCrossing = Updown[1:len(Updown)] * Updown[0:len(Updown) - 1]\n","        jump_index = np.where(Updown_XeroCrossing < 0)\n","        numberOfblinks = int(len(jump_index[0]) / 2)\n","        selected_EAR_First = XtremaEAR[jump_index[0]]\n","        selected_EAR_Sec = XtremaEAR[jump_index[0] + 1]\n","        selected_index_First = xtrema_index[jump_index[0]]\n","        selected_index_Sec = xtrema_index[jump_index[0] + 1]\n","        if numberOfblinks>1:\n","            MISSED_BLINKS=True\n","        if numberOfblinks ==0:\n","            print(Updown,Last_Blink.duration)\n","            print(values)\n","            print(Derivative)\n","        for j in range(numberOfblinks):\n","            detected_blink=Blink()\n","            detected_blink.start=selected_index_First[2*j]\n","            detected_blink.peak = selected_index_Sec[2*j]\n","            detected_blink.end = selected_index_Sec[2*j + 1]\n","\n","            detected_blink.startEAR=selected_EAR_First[2*j]\n","            detected_blink.peakEAR = selected_EAR_Sec[2*j]\n","            detected_blink.endEAR = selected_EAR_Sec[2*j + 1]\n","\n","            detected_blink.duration=detected_blink.end-detected_blink.start+1\n","            detected_blink.amplitude=0.5*(detected_blink.startEAR-detected_blink.peakEAR)+0.5*(detected_blink.endEAR-detected_blink.peakEAR)\n","            detected_blink.velocity=(detected_blink.endEAR-selected_EAR_First[2*j+1])/(detected_blink.end-selected_index_First[2*j+1]+1) #eye opening ave velocity\n","            retrieved_blinks.append(detected_blink)\n","\n","\n","\n","        return MISSED_BLINKS,retrieved_blinks\n","\n","\n","\n","    def Blink_Tracker(EAR,IF_Closed_Eyes,Counter4blinks,TOTAL_BLINKS,skip):\n","        BLINK_READY=False\n","        #If the eyes are closed\n","        if int(IF_Closed_Eyes)==1:\n","            Current_Blink.values.append(EAR)\n","            Current_Blink.EAR_of_FOI=EAR      #Save to use later\n","            if Counter4blinks>0:\n","                skip = False\n","            if Counter4blinks==0:\n","                Current_Blink.startEAR=EAR    #EAR_series[6] is the EAR for the frame of interest(the middle one)\n","                Current_Blink.start=reference_frame-6   #reference-6 points to the frame of interest which will be the 'start' of the blink\n","            Counter4blinks += 1\n","            if Current_Blink.peakEAR>=EAR:    #deciding the min point of the EAR signal\n","                Current_Blink.peakEAR =EAR\n","                Current_Blink.peak=reference_frame-6\n","\n","\n","\n","\n","\n","        # otherwise, the eyes are open in this frame\n","        else:\n","\n","            if Counter4blinks <2 and skip==False :           # Wait to approve or reject the last blink\n","                if Last_Blink.duration>15:\n","                    FRAME_MARGIN_BTW_2BLINKS=8\n","                else:\n","                    FRAME_MARGIN_BTW_2BLINKS=1\n","                if ( (reference_frame-6) - Last_Blink.end) > FRAME_MARGIN_BTW_2BLINKS:\n","                    # Check so the prev blink signal is not monotonic or too small (noise)\n","                    if  Last_Blink.peakEAR < Last_Blink.startEAR and Last_Blink.peakEAR < Last_Blink.endEAR and Last_Blink.amplitude>MIN_AMPLITUDE and Last_Blink.start<Last_Blink.peak:\n","                        if((Last_Blink.startEAR - Last_Blink.peakEAR)> (Last_Blink.endEAR - Last_Blink.peakEAR)*0.25 and (Last_Blink.startEAR - Last_Blink.peakEAR)*0.25< (Last_Blink.endEAR - Last_Blink.peakEAR)): # the amplitude is balanced\n","                            BLINK_READY = True\n","                            #####THE ULTIMATE BLINK Check\n","\n","                            Last_Blink.values=signal.convolve1d(Last_Blink.values, [1/3.0, 1/3.0,1/3.0],mode='nearest')\n","                            # Last_Blink.values=signal.median_filter(Last_Blink.values, 3, mode='reflect')   # smoothing the signal\n","                            [MISSED_BLINKS,retrieved_blinks]=Ultimate_Blink_Check()\n","                            #####\n","                            TOTAL_BLINKS =TOTAL_BLINKS+len(retrieved_blinks)  # Finally, approving/counting the previous blink candidate\n","                            ###Now You can count on the info of the last separate and valid blink and analyze it\n","                            Counter4blinks = 0\n","                            print(\"MISSED BLINKS= {}\".format(len(retrieved_blinks)))\n","                            return retrieved_blinks,int(TOTAL_BLINKS),Counter4blinks,BLINK_READY,skip\n","                        else:\n","                            skip=True\n","                            print('rejected due to imbalance')\n","                    else:\n","                        skip = True\n","                        print('rejected due to noise,magnitude is {}'.format(Last_Blink.amplitude))\n","                        print(Last_Blink.start<Last_Blink.peak)\n","\n","            # if the eyes were closed for a sufficient number of frames (2 or more)\n","            # then this is a valid CANDIDATE for a blink\n","            if Counter4blinks >1:\n","                Current_Blink.end = reference_frame - 7  #reference-7 points to the last frame that eyes were closed\n","                Current_Blink.endEAR=Current_Blink.EAR_of_FOI\n","                Current_Blink.amplitude = (Current_Blink.startEAR + Current_Blink.endEAR - 2 * Current_Blink.peakEAR) / 2\n","                Current_Blink.duration = Current_Blink.end - Current_Blink.start + 1\n","\n","                if Last_Blink.duration>15:\n","                    FRAME_MARGIN_BTW_2BLINKS=8\n","                else:\n","                    FRAME_MARGIN_BTW_2BLINKS=1\n","                if (Current_Blink.start-Last_Blink.end )<=FRAME_MARGIN_BTW_2BLINKS+1:  #Merging two close blinks\n","                    print('Merging...')\n","                    frames_in_between=Current_Blink.start - Last_Blink.end-1\n","                    print(Current_Blink.start ,Last_Blink.end, frames_in_between)\n","                    valuesBTW=Linear_Interpolate(Last_Blink.endEAR,Current_Blink.startEAR,frames_in_between)\n","                    Last_Blink.values=Last_Blink.values+valuesBTW+Current_Blink.values\n","                    Last_Blink.end = Current_Blink.end            # update the end\n","                    Last_Blink.endEAR = Current_Blink.endEAR\n","                    if Last_Blink.peakEAR>Current_Blink.peakEAR:  #update the peak\n","                        Last_Blink.peakEAR=Current_Blink.peakEAR\n","                        Last_Blink.peak = Current_Blink.peak\n","                        #update duration and amplitude\n","                    Last_Blink.amplitude = (Last_Blink.startEAR + Last_Blink.endEAR - 2 * Last_Blink.peakEAR) / 2\n","                    Last_Blink.duration = Last_Blink.end - Last_Blink.start + 1\n","                else:                                             #Should not Merge (a Separate blink)\n","\n","                    Last_Blink.values=Current_Blink.values        #update the EAR list\n","\n","\n","                    Last_Blink.end = Current_Blink.end            # update the end\n","                    Last_Blink.endEAR = Current_Blink.endEAR\n","\n","                    Last_Blink.start = Current_Blink.start        #update the start\n","                    Last_Blink.startEAR = Current_Blink.startEAR\n","\n","                    Last_Blink.peakEAR = Current_Blink.peakEAR    #update the peak\n","                    Last_Blink.peak = Current_Blink.peak\n","\n","                    Last_Blink.amplitude = Current_Blink.amplitude\n","                    Last_Blink.duration = Current_Blink.duration\n","\n","\n","\n","\n","            # reset the eye frame counter\n","            Counter4blinks = 0\n","        retrieved_blinks=0\n","        return retrieved_blinks,int(TOTAL_BLINKS),Counter4blinks,BLINK_READY,skip\n","\n","\n","\n","\n","    print('Starting')\n","    #\n","\n","\n","    # initialize the frame counters and the total number of yawnings\n","    COUNTER = 0\n","    MCOUNTER=0\n","    TOTAL = 0\n","    MTOTAL=0\n","    TOTAL_BLINKS=0\n","    Counter4blinks=0\n","    skip=False # to make sure a blink is not counted twice in the Blink_Tracker function\n","    Last_Blink=Blink()\n","\n","    print(\"[INFO] loading facial landmark predictor...\")\n","    detector = dlib.get_frontal_face_detector()\n","    #Load the Facial Landmark Detector\n","    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n","    #Load the Blink Detector\n","    loaded_svm = pickle.load(open('Trained_SVM_C=1000_gamma=0.1_for 7kNegSample.sav', 'rb'))\n","    # grab the indexes of the facial landmarks for the left and\n","    # right eye, respectively\n","    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n","    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n","    (mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n","    print(\"[INFO] starting video stream thread...\")\n","\n","\n","\n","\n","\n","    lk_params=dict( winSize  = (13,13),\n","                        maxLevel = 2,\n","                        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","    EAR_series=np.zeros([13])\n","    Frame_series=np.linspace(1,13,13)\n","    reference_frame=0\n","    First_frame=True\n","    top = tk.Tk()\n","    frame1 = Frame(top)\n","    frame1.grid(row=0, column=0)\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    plot_frame =FigureCanvasTkAgg(fig, master=frame1)\n","    plot_frame.get_tk_widget().pack(side=tk.BOTTOM, expand=True)\n","    plt.ylim([0.0, 0.5])\n","    line, = ax.plot(Frame_series,EAR_series)\n","    plot_frame.draw()\n","\n","    # loop over frames from the video stream\n","\n","\n","    stream = cv2.VideoCapture(path)\n","    start = datetime.datetime.now()\n","    number_of_frames=0\n","    while True:\n","        (grabbed, frame) = stream.read()\n","        if not grabbed:\n","            print('not grabbed')\n","            print(number_of_frames)\n","            break\n","\n","\n","        frame = imutils.resize(frame, width=450)\n","\n","        # To Rotate by 90 degreees\n","        rows=np.shape(frame)[0]\n","        cols = np.shape(frame)[1]\n","        M = cv2.getRotationMatrix2D((cols / 2, rows / 2),-90, 1)\n","        frame = cv2.warpAffine(frame, M, (cols, rows))\n","\n","\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)   #Brighten the image(Gamma correction)\n","        reference_frame = reference_frame + 1\n","        gray=adjust_gamma(gray,gamma=1.5)\n","        Q.put(frame)\n","        end = datetime.datetime.now()\n","        ElapsedTime=(end - start).total_seconds()\n","\n","\n","\n","\n","        # detect faces in the grayscale frame\n","        rects = detector(gray, 0)\n","        if (np.size(rects) != 0):\n","            number_of_frames = number_of_frames + 1  # we only consider frames that face is detected\n","            First_frame = False\n","            old_gray = gray.copy()\n","            # determine the facial landmarks for the face region, then\n","            # convert the facial landmark (x, y)-coordinates to a NumPy\n","            # array\n","            shape = predictor(gray, rects[0])\n","            shape = face_utils.shape_to_np(shape)\n","\n","            ###############YAWNING##################\n","            #######################################\n","            Mouth = shape[mStart:mEnd]\n","            MAR = mouth_aspect_ratio(Mouth)\n","\n","\n","            MouthHull = cv2.convexHull(Mouth)\n","            cv2.drawContours(frame, [MouthHull], -1, (255, 0, 0), 1)\n","\n","            if MAR > MOUTH_AR_THRESH:\n","               MCOUNTER += 1\n","\n","            elif MAR < MOUTH_AR_THRESH_ALERT:\n","\n","                if MCOUNTER >= MOUTH_AR_CONSEC_FRAMES:\n","                    MTOTAL += 1\n","\n","                MCOUNTER = 0\n","\n","\n","            ##############YAWNING####################\n","            #########################################\n","\n","            # extract the left and right eye coordinates, then use the\n","            # coordinates to compute the eye aspect ratio for both eyes\n","\n","            leftEye = shape[lStart:lEnd]\n","            rightEye = shape[rStart:rEnd]\n","            leftEAR = eye_aspect_ratio(leftEye)\n","            rightEAR = eye_aspect_ratio(rightEye)\n","\n","            # average the eye aspect ratio together for both eyes\n","            ear = (leftEAR + rightEAR) / 2.0\n","            #EAR_series[reference_frame]=ear\n","            EAR_series = shift(EAR_series, -1, cval=ear)\n","\n","            # compute the convex hull for the left and right eye, then\n","            # visualize each of the eyes\n","            leftEyeHull = cv2.convexHull(leftEye)\n","            rightEyeHull = cv2.convexHull(rightEye)\n","            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n","            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n","\n","            ############HANDLING THE EMERGENCY SITATION################\n","            ###########################################################\n","            ###########################################################\n","            COUNTER=EMERGENCY(ear,COUNTER)\n","\n","             # EMERGENCY SITUATION (EYES TOO LONG CLOSED) ALERT THE DRIVER IMMEDIATELY\n","            ############HANDLING THE EMERGENCY SITATION################\n","            ###########################################################\n","            ###########################################################\n","\n","            if Q.full() and (reference_frame>15):  #to make sure the frame of interest for the EAR vector is int the mid\n","                EAR_table = EAR_series\n","                IF_Closed_Eyes = loaded_svm.predict(EAR_series.reshape(1,-1))\n","                if Counter4blinks==0:\n","                    Current_Blink = Blink()\n","                retrieved_blinks, TOTAL_BLINKS, Counter4blinks, BLINK_READY, skip = Blink_Tracker(EAR_series[6],\n","                                                                                                      IF_Closed_Eyes,\n","                                                                                                      Counter4blinks,\n","                                                                                                      TOTAL_BLINKS, skip)\n","                if (BLINK_READY==True):\n","                    reference_frame=20   #initialize to a random number to avoid overflow in large numbers\n","                    skip = True\n","                    #####\n","                    BLINK_FRAME_FREQ = TOTAL_BLINKS / number_of_frames\n","                    for detected_blink in retrieved_blinks:\n","                        print(detected_blink.amplitude, Last_Blink.amplitude)\n","                        print(detected_blink.duration, detected_blink.velocity)\n","                        print('-------------------')\n","\n","                        if(detected_blink.velocity>0):\n","                          with open(output_file, 'ab') as f_handle:\n","                             f_handle.write(b'\\n')\n","                             np.savetxt(f_handle,[TOTAL_BLINKS,BLINK_FRAME_FREQ*100,detected_blink.amplitude,detected_blink.duration,detected_blink.velocity], delimiter=', ', newline=' ',fmt='%.4f')\n","\n","\n","\n","\n","\n","                    Last_Blink.end = -10 # re initialization\n","                    #####\n","\n","                line.set_ydata(EAR_series)\n","                plot_frame.draw()\n","                frameMinus7=Q.get()\n","                cv2.imshow(\"Frame\", frameMinus7)\n","            elif Q.full():         #just to make way for the new input of the Q when the Q is full\n","                junk =  Q.get()\n","\n","            key = cv2.waitKey(1) & 0xFF\n","\n","            # if the `q` key was pressed, break from the loop\n","            if key != 0xFF:\n","                break\n","        #Does not detect any face\n","        else:\n","            ###################Using Optical Flow############\n","            ###################    (Optional)    ############\n","            st=0\n","            st2=0\n","            if (First_frame == False):\n","                leftEye=leftEye.astype(np.float32)\n","                rightEye = rightEye.astype(np.float32)\n","                p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, gray,leftEye, None, **lk_params)\n","                p2, st2, err2 = cv2.calcOpticalFlowPyrLK(old_gray, gray, rightEye, None, **lk_params)\n","\n","            if np.sum(st)+np.sum(st2)==12 and First_frame==False:\n","\n","                p1 = np.round(p1).astype(np.int)\n","                p2 = np.round(p2).astype(np.int)\n","                #print(p1)\n","\n","                leftEAR = eye_aspect_ratio(p1)\n","                rightEAR = eye_aspect_ratio(p2)\n","\n","                ear = (leftEAR + rightEAR) / 2.0\n","                EAR_series = shift(EAR_series, -1, cval=ear)\n","                #EAR_series[reference_frame] = ear\n","                leftEyeHull = cv2.convexHull(p1)\n","                rightEyeHull = cv2.convexHull(p2)\n","                cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n","                cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n","                old_gray = gray.copy()\n","                leftEye = p1\n","                rightEye = p2\n","                ############HANDLING THE EMERGENCY SITATION################\n","                ###########################################################\n","                ###########################################################\n","                COUNTER = EMERGENCY(ear, COUNTER)\n","                ############HANDLING THE EMERGENCY SITATION################\n","                ###########################################################\n","                ###########################################################\n","\n","\n","            ###################Using Optical Flow############\n","            ###################                  ############\n","\n","            if Q.full() and (reference_frame>15):\n","                EAR_table = EAR_series\n","                IF_Closed_Eyes = loaded_svm.predict(EAR_series.reshape(1,-1))\n","                if Counter4blinks==0:\n","                    Current_Blink = Blink()\n","                    retrieved_blinks, TOTAL_BLINKS, Counter4blinks, BLINK_READY, skip = Blink_Tracker(EAR_series[6],\n","                                                                                                      IF_Closed_Eyes,\n","                                                                                                      Counter4blinks,\n","                                                                                                      TOTAL_BLINKS, skip)\n","                if (BLINK_READY==True):\n","                    reference_frame=20   #initialize to a random number to avoid overflow in large numbers\n","                    skip = True\n","                    #####\n","                    BLINK_FRAME_FREQ = TOTAL_BLINKS / number_of_frames\n","                    for detected_blink in retrieved_blinks:\n","                        print(detected_blink.amplitude, Last_Blink.amplitude)\n","                        print(detected_blink.duration, Last_Blink.duration)\n","                        print('-------------------')\n","                        with open(output_file, 'ab') as f_handle:\n","                            f_handle.write(b'\\n')\n","                            np.savetxt(f_handle,[TOTAL_BLINKS,BLINK_FRAME_FREQ*100,detected_blink.amplitude,detected_blink.duration,detected_blink.velocity], delimiter=', ', newline=' ',fmt='%.4f')\n","\n","                    Last_Blink.end = -10 # re initialization\n","\n","\n","                    #####\n","\n","                line.set_ydata(EAR_series)\n","                plot_frame.draw()\n","                frameMinus7=Q.get()\n","                cv2.imshow(\"Frame\", frameMinus7)\n","            elif Q.full():\n","                junk = Q.get()\n","\n","            key = cv2.waitKey(1) & 0xFF\n","\n","\n","            if key != 0xFF:\n","                 break\n","\n","    # do a bit of cleanup\n","    stream.release()\n","    cv2.destroyAllWindows()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"hS7wXmx0LtAR","colab_type":"code","colab":{},"outputId":"8b5f0bb3-4551-4c14-8a37-d75730a8193b"},"source":["#############\n","####Main#####\n","#############\n","\n","output_file = 'alert.txt'  # The text file to write to (for blinks)#\n","path = 'D:\\\\Fold1_part1\\\\01\\\\0.mov' # the path to the input video\n","blink_detector(output_file,path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting\n","[INFO] loading facial landmark predictor...\n"],"name":"stdout"},{"output_type":"stream","text":["C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:311: UserWarning: Trying to unpickle estimator SVC from version pre-0.18 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[INFO] starting video stream thread...\n","rejected due to noise,magnitude is -0.5\n","False\n","MISSED BLINKS= 1\n","0.0784332390168781 0.11659228346400011\n","8 0.01830673891909813\n","-------------------\n","MISSED BLINKS= 1\n","0.12730310737485326 0.1432187195929538\n","10 0.016951813347369837\n","-------------------\n","MISSED BLINKS= 1\n","0.16059371880607523 0.17139470907541943\n","8 0.031588947705140744\n","-------------------\n","[1. 1.] 3\n","[0.27980627 0.25821247 0.23661867]\n","[-0.0215938 -0.0215938]\n","MISSED BLINKS= 0\n","MISSED BLINKS= 1\n","0.1150139714639879 0.14372415356008902\n","9 0.018830509687184957\n","-------------------\n","MISSED BLINKS= 1\n","0.11875419365605278 0.15645266216372725\n","8 0.02170630345377438\n","-------------------\n","MISSED BLINKS= 1\n","0.17561816134005043 0.20272371318856716\n","12 0.021634262640208533\n","-------------------\n","MISSED BLINKS= 1\n","0.15026979937890006 0.17286652635932173\n","11 0.017752495422405166\n","-------------------\n","MISSED BLINKS= 1\n","0.12442032809455103 0.194192288804551\n","9 0.02032550685091495\n","-------------------\n","MISSED BLINKS= 1\n","0.09913035896231068 0.09113835686743485\n","8 0.018063327737937396\n","-------------------\n","MISSED BLINKS= 1\n","0.09388745577553151 0.13601028945728835\n","8 0.015014436989939697\n","-------------------\n","Merging...\n","55 53 1\n","MISSED BLINKS= 1\n","0.058703553256678476 0.07182238948880929\n","10 0.011003703110521726\n","-------------------\n","rejected due to noise,magnitude is 0.022464095853018867\n","True\n","[1. 1.] 3\n","[0.30176587 0.31045205 0.31913823]\n","[0.00868618 0.00868618]\n","MISSED BLINKS= 0\n","MISSED BLINKS= 1\n","0.1382140235593851 0.1710636660741732\n","10 0.01968194710577003\n","-------------------\n","rejected due to noise,magnitude is 0.040436179297505676\n","False\n","MISSED BLINKS= 1\n","0.07211917866848166 0.09291907987409095\n","7 0.020263425086592023\n","-------------------\n","rejected due to noise,magnitude is 0.023683581553704647\n","True\n","MISSED BLINKS= 1\n","0.04423826213871265 0.07228159819299934\n","5 0.012736867689368584\n","-------------------\n","MISSED BLINKS= 1\n","0.1647695925156873 0.20572160926228494\n","12 0.021081311189691938\n","-------------------\n","MISSED BLINKS= 1\n","0.0779331535347601 0.14332780062575268\n","6 0.01814271265040493\n","-------------------\n","MISSED BLINKS= 1\n","0.10302297765921126 0.15741900997028307\n","9 0.017669059355014227\n","-------------------\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-1b749bf3b819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'alert.txt'\u001b[0m  \u001b[1;31m# The text file to write to (for blinks)#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D:\\\\Fold1_part1\\\\01\\\\0.mov'\u001b[0m \u001b[1;31m# the path to the input video\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mblink_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m<ipython-input-4-9243ef34ae7d>\u001b[0m in \u001b[0;36mblink_detector\u001b[1;34m(output_textfile, input_video)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;31m# detect faces in the grayscale frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrects\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m             \u001b[0mnumber_of_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumber_of_frames\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# we only consider frames that face is detected\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mFirst_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"g1R2KZmQLtAb","colab_type":"code","colab":{}},"source":["cv2.destroyAllWindows()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIQP0GE3LtAj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}